{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":722918,"sourceType":"datasetVersion","datasetId":342174}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-25T03:57:23.331429Z","iopub.execute_input":"2025-06-25T03:57:23.331742Z","iopub.status.idle":"2025-06-25T03:57:23.339514Z","shell.execute_reply.started":"2025-06-25T03:57:23.331709Z","shell.execute_reply":"2025-06-25T03:57:23.338406Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"\n\"\"\"paper_pipeline_pseudocode.py\n--------------------------------\nCompanion pseudo‑code for the manuscript:\n“Predicting Antibiotic Resistance in *Neisseria gonorrhoeae* Clinical Isolates\n Using Machine‑ and Deep‑Learning”\n\nThis file is NOT meant to be executed as‑is; it captures the logical flow,\nkey algorithmic choices, and hyper‑parameters described in the paper in a\nreadable Pythonic format for reviewers and readers.\n\n⚑  Replace each `TODO` section with concrete implementation details if you\n   intend to run the pipeline.\n\"\"\"\n\n# ───────────────────────────────────────────────────────────────────────────────\n# 0. Imports & constants\n# ───────────────────────────────────────────────────────────────────────────────\nfrom pathlib import Path\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score,\n    f1_score, roc_auc_score, matthews_corrcoef\n)\nfrom lazypredict.Supervised import LazyClassifier\nfrom catboost import CatBoostClassifier\nfrom keras.models import Sequential\nfrom keras.layers import Dense, BatchNormalization, Dropout\nfrom keras.optimizers import Adam\nimport shap  # SHAP explainability\n# DeLong: see https://github.com/Netflix/vmaf/blob/master/python/setup.py or\n# external libraries such as `deltapy`\n# TODO: import DeLong test implementation (or custom function)\n\nRNG_SEED = 42\nN_FOLDS = 5\nDATA_CSV = Path(\"metadata.csv\")\n\n# ───────────────────────────────────────────────────────────────────────────────\n# 1. Load & basic EDA\n# ───────────────────────────────────────────────────────────────────────────────\ndef load_data(csv_path: Path) -> pd.DataFrame:\n    \"\"\"Load the surveillance metadata.\"\"\"\n    df = pd.read_csv(csv_path)\n    # TODO: perform sanity checks (shape, dtypes)\n    return df\n\n\ndef basic_eda(df: pd.DataFrame) -> None:\n    \"\"\"Lightweight EDA: value counts, missingness, skew, etc.\"\"\"\n    # TODO: summarise distributions, skewness, and visualize if needed\n    pass\n\n\n# ───────────────────────────────────────────────────────────────────────────────\n# 2. Pre‑processing\n# ───────────────────────────────────────────────────────────────────────────────\ndef preprocess(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Impute missing values and label‑encode categorical columns.\"\"\"\n    # example strategy from the paper:\n    for col in df.columns:\n        if df[col].dtype.kind in \"biufc\":  # numeric\n            skew = df[col].skew()\n            if skew > 1:\n                df[col] = df[col].fillna(df[col].mean())\n            elif skew < -1:\n                df[col] = df[col].fillna(df[col].median())\n            else:\n                df[col] = df[col].fillna(df[col].median())\n        else:  # categorical\n            df[col] = df[col].fillna(df[col].mode()[0])\n            df[col] = df[col].astype(\"category\").cat.codes\n    return df\n\n\n# ───────────────────────────────────────────────────────────────────────────────\n# 3. Feature / target split helper\n# ───────────────────────────────────────────────────────────────────────────────\nANTIBIOTICS = {\"azm_sr\": \"Azithromycin\",\n               \"cip_sr\": \"Ciprofloxacin\",\n               \"cfx_sr\": \"Cefixime\"}\n\n\ndef make_xy(df: pd.DataFrame, target_key: str):\n    \"\"\"Return X, y numpy arrays for a given antibiotic resistance column.\"\"\"\n    y = df[target_key].values\n    X = df.drop(columns=list(ANTIBIOTICS.keys())).values\n    return X, y\n\n\n# ───────────────────────────────────────────────────────────────────────────────\n# 4. Baseline benchmarking using LazyPredict\n# ───────────────────────────────────────────────────────────────────────────────\ndef benchmark_models(X, y):\n    \"\"\"Run 32 default classifiers to establish a performance floor.\"\"\"\n    clf = LazyClassifier(verbose=0, random_state=RNG_SEED, predictions=False)\n    models, _ = clf.fit(X, X, y, y)  # train==test for quick listing\n    return models.sort_values(\"Accuracy\", ascending=False)\n\n\n# ───────────────────────────────────────────────────────────────────────────────\n# 5. CatBoost with Bayesian optimisation\n# ───────────────────────────────────────────────────────────────────────────────\ndef train_catboost(X, y):\n    \"\"\"Tune CatBoost hyper‑parameters via Bayesian optimisation.\"\"\"\n    # Hyper‑parameter search space\n    param_bounds = {\n        \"depth\": (4, 10),\n        \"learning_rate\": (0.005, 0.3),\n        \"l2_leaf_reg\": (1, 10),\n    }\n    # TODO: use scikit‑optimize / optuna to iterate and maximise AUC\n    best_params = {\"depth\": 6, \"learning_rate\": 0.05, \"l2_leaf_reg\": 3}\n    model = CatBoostClassifier(\n        **best_params,\n        loss_function=\"Logloss\",\n        eval_metric=\"AUC\",\n        random_seed=RNG_SEED,\n        verbose=False\n    )\n    model.fit(X, y)\n    return model\n\n\n# ───────────────────────────────────────────────────────────────────────────────\n# 6. Keras feed‑forward neural network\n# ───────────────────────────────────────────────────────────────────────────────\ndef build_ffnn(input_dim: int) -> Sequential:\n    \"\"\"Return a compiled 3‑layer feed‑forward network.\"\"\"\n    model = Sequential([\n        Dense(256, activation=\"relu\", input_shape=(input_dim,)),\n        BatchNormalization(),\n        Dropout(0.3),\n        Dense(64, activation=\"relu\"),\n        BatchNormalization(),\n        Dropout(0.3),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=Adam(learning_rate=0.001),\n                  loss=\"binary_crossentropy\",\n                  metrics=[\"AUC\", \"accuracy\"])\n    return model\n\n\n# ───────────────────────────────────────────────────────────────────────────────\n# 7. Cross‑validation evaluation\n# ───────────────────────────────────────────────────────────────────────────────\ndef cv_evaluate(model_fn, X, y, model_type=\"catboost\"):\n    \"\"\"Stratified K‑fold CV returning key metrics.\"\"\"\n    skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RNG_SEED)\n    metrics = {\"AUC\": [], \"F1\": [], \"MCC\": []}\n\n    for train_idx, test_idx in skf.split(X, y):\n        X_train, X_test = X[train_idx], X[test_idx]\n        y_train, y_test = y[train_idx], y[test_idx]\n\n        if model_type == \"ffnn\":\n            model = model_fn(X_train.shape[1])\n            model.fit(X_train, y_train, epochs=50, batch_size=32,\n                      verbose=0, validation_split=0.1)\n            y_prob = model.predict(X_test).ravel()\n        else:  # catboost or any scikit‑compatible model\n            model = model_fn(X_train, y_train)\n            y_prob = model.predict_proba(X_test)[:, 1]\n\n        y_pred = (y_prob >= 0.5).astype(int)\n        metrics[\"AUC\"].append(roc_auc_score(y_test, y_prob))\n        metrics[\"F1\"].append(f1_score(y_test, y_pred))\n        metrics[\"MCC\"].append(matthews_corrcoef(y_test, y_pred))\n\n    return {k: np.mean(v) for k, v in metrics.items()}\n\n\n# ───────────────────────────────────────────────────────────────────────────────\n# 8. Statistical comparison (DeLong)\n# ───────────────────────────────────────────────────────────────────────────────\ndef delong_test(preds1, preds2, y_true):\n    \"\"\"Return p‑value comparing two ROC AUCs (placeholder).\"\"\"\n    # TODO: insert DeLong implementation or use `scikit‑posthocs`\n    raise NotImplementedError\n\n\n# ───────────────────────────────────────────────────────────────────────────────\n# 9. SHAP explainability\n# ───────────────────────────────────────────────────────────────────────────────\ndef explain_with_shap(model, X):\n    \"\"\"Compute SHAP values and return summary DataFrame.\"\"\"\n    explainer = shap.TreeExplainer(model)\n    shap_values = explainer.shap_values(X)\n    shap.summary_plot(shap_values, X, show=False)\n    # TODO: save figure or return per‑feature mean(|SHAP|)\n    pass\n\n\n# ───────────────────────────────────────────────────────────────────────────────\n# 10. Orchestration\n# ───────────────────────────────────────────────────────────────────────────────\ndef main():\n    df = load_data(DATA_CSV)\n    basic_eda(df)\n\n    df_clean = preprocess(df)\n\n    for target in ANTIBIOTICS.keys():\n        X, y = make_xy(df_clean, target)\n\n        # Baseline benchmarks\n        baselines = benchmark_models(X, y)\n        print(f\"\\nTop‑5 baseline models for {target}:\\n\", baselines.head())\n\n        # CatBoost\n        cat_metrics = cv_evaluate(train_catboost, X, y, model_type=\"catboost\")\n        print(f\"CatBoost CV metrics for {target}:\", cat_metrics)\n\n        # Neural net\n        nn_metrics = cv_evaluate(build_ffnn, X, y, model_type=\"ffnn\")\n        print(f\"Neural Net CV metrics for {target}:\", nn_metrics)\n\n        # TODO: external validation subset evaluation\n        # TODO: DeLong tests comparing CatBoost vs literature\n\n        # Explainability\n        cat_model = train_catboost(X, y)\n        explain_with_shap(cat_model, X)\n\n    print(\"Pipeline complete.\")\n\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T03:57:23.385301Z","iopub.execute_input":"2025-06-25T03:57:23.385633Z","iopub.status.idle":"2025-06-25T03:57:23.398364Z","shell.execute_reply.started":"2025-06-25T03:57:23.385600Z","shell.execute_reply":"2025-06-25T03:57:23.397071Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}